{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec (Negative Sampling)\n",
    "\n",
    "2 things we need to add\n",
    "- how to sample the negative samples\n",
    "- the process of getting the negative samples\n",
    "\n",
    "1 thing we need to change:\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.24.0', '1.12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__, torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the sentences / corpus\n",
    "#corpus is defined as a set of documents\n",
    "#document is basically a bunch of sentence(s)\n",
    "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\", \"grape apple apple\", \n",
    "          \"dog cat animal\", \"cat dog animal\", \"cat animal dog\", \"fish dog dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['apple', 'banana', 'fruit'],\n",
       " ['banana', 'apple', 'fruit'],\n",
       " ['banana', 'fruit', 'apple'],\n",
       " ['grape', 'apple', 'apple'],\n",
       " ['dog', 'cat', 'animal'],\n",
       " ['cat', 'dog', 'animal'],\n",
       " ['cat', 'animal', 'dog'],\n",
       " ['fish', 'dog', 'dog']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. tokenize\n",
    "#usually you use spaCy / NLTK to tokenize (but we gonna do this later on, we gonna have spaCy)\n",
    "corpus_tokenized = [sent.split(\" \") for sent in corpus]\n",
    "corpus_tokenized  #we called each of this as \"tokens\", NOT words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. numericalize\n",
    "\n",
    "#2.1 get all the unique words\n",
    "#we want to flatten this (basically merge all list)\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "vocabs  = list(set(flatten(corpus_tokenized)))  #vocabs is a term defining all unique words your system know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 assign id to all these vocabs\n",
    "word2index = {v: idx for idx, v in enumerate(vocabs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add <UNK>, which is a very normal token exists in the world\n",
    "vocabs.append('<UNK>') #chaky, can it be ##UNK, or UNKKKKKK, or anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have a way to know what is the id of <UNK>\n",
    "word2index['<UNK>'] = 6  #usually <UNK> is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'banana',\n",
       " 1: 'cat',\n",
       " 2: 'grape',\n",
       " 3: 'fruit',\n",
       " 4: 'fish',\n",
       " 5: 'apple',\n",
       " 6: '<UNK>',\n",
       " 7: 'dog'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create index2word dictionary\n",
    "#2 min    \n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['banana', 'cat', 'grape', 'fruit', 'fish', 'apple', 'animal', 'dog', '<UNK>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare train data\n",
    "You move the window along, and create those tuples as we said in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['banana', 'apple'],\n",
       " ['banana', 'fruit'],\n",
       " ['apple', 'banana'],\n",
       " ['apple', 'fruit'],\n",
       " ['fruit', 'banana'],\n",
       " ['fruit', 'apple'],\n",
       " ['apple', 'grape'],\n",
       " ['apple', 'apple'],\n",
       " ['cat', 'dog'],\n",
       " ['cat', 'animal'],\n",
       " ['dog', 'cat'],\n",
       " ['dog', 'animal'],\n",
       " ['animal', 'cat'],\n",
       " ['animal', 'dog'],\n",
       " ['dog', 'fish'],\n",
       " ['dog', 'dog']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move along the corpus\n",
    "#to fit with our corpus, we gonna use window_size = 1\n",
    "\n",
    "skipgrams = []\n",
    "\n",
    "#for each corpus\n",
    "for sent in corpus_tokenized:\n",
    "    #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
    "    for i in range(1, len(sent) - 1): #start from 1 to second last\n",
    "        center_word = sent[i]\n",
    "        outside_words = [sent[i-1], sent[i+1]]  #window_size = 1\n",
    "        for o in outside_words:\n",
    "            skipgrams.append([center_word, o])\n",
    "\n",
    "skipgrams\n",
    "        \n",
    "#here we want to create (banana, apple), (banana, fruit) append to some list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make what we have made into a function (batch function)\n",
    "#return a batches of data, e.g., =2 --> ['banana', 'apple'], ['banana', 'fruit']\n",
    "#also i want these batches to be id, NOT token   --> [5, 4]\n",
    "\n",
    "def random_batch(batch_size, corpus):\n",
    "    \n",
    "    skipgrams = []\n",
    "\n",
    "    #for each corpus\n",
    "    for sent in corpus_tokenized:\n",
    "        #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
    "        for i in range(1, len(sent) - 1): #start from 1 to second last\n",
    "            center_word = word2index[sent[i]]\n",
    "            outside_words = [word2index[sent[i-1]], word2index[sent[i+1]]]  #window_size = 1\n",
    "            for o in outside_words:\n",
    "                skipgrams.append([center_word, o])\n",
    "                \n",
    "    #only get a batch, not the entire list\n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
    "             \n",
    "    #appending some list of inputs and labels\n",
    "    random_inputs, random_labels = [], []   \n",
    "    for index in random_index:\n",
    "        random_inputs.append([skipgrams[index][0]])  #center words, this will be a shape of (1, ) --> (1, 1) for modeling\n",
    "        random_labels.append([skipgrams[index][1]])\n",
    "        \n",
    "    return np.array(random_inputs), np.array(random_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "label=array([[3],\n",
      "       [4],\n",
      "       [6],\n",
      "       [0],\n",
      "       [0],\n",
      "       [3],\n",
      "       [1],\n",
      "       [7],\n",
      "       [1],\n",
      "       [2]])\n"
     ]
    }
   ],
   "source": [
    "input, label = random_batch(10, corpus_tokenized)\n",
    "\n",
    "print(f\"{input.shape}\")\n",
    "print(f\"{label=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unigram distribution\n",
    "\n",
    "$$P(w)=U(w)^{3/4}/Z$$\n",
    "\n",
    "Defining the probability of sampling negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basically create a distribution of all the words you have in your vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0.001  #scaling up low frequency terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'apple': 5,\n",
       "         'banana': 3,\n",
       "         'fruit': 3,\n",
       "         'grape': 1,\n",
       "         'dog': 5,\n",
       "         'cat': 3,\n",
       "         'animal': 3,\n",
       "         'fish': 1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count all the occurrences of vocabs\n",
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(flatten(corpus_tokenized))\n",
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_total_words = sum([c for w, c in word_count.items()])\n",
    "num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'banana': 210,\n",
       "         'cat': 210,\n",
       "         'grape': 92,\n",
       "         'fruit': 210,\n",
       "         'fish': 92,\n",
       "         'apple': 308,\n",
       "         'animal': 210,\n",
       "         'dog': 308})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_table = []\n",
    "\n",
    "for v in vocabs:\n",
    "    uw = word_count[v]/num_total_words\n",
    "    uw_alpha = uw ** 0.75\n",
    "    uw_alpha_dividebyz = int(uw_alpha / z)\n",
    "    # print(\"vocab: \", v)\n",
    "    # print(\"distribution: \", uw_alpha_dividebyz)\n",
    "    unigram_table.extend([v] * uw_alpha_dividebyz)\n",
    "    \n",
    "Counter(unigram_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'apple': 5,\n",
       "         'banana': 3,\n",
       "         'fruit': 3,\n",
       "         'grape': 1,\n",
       "         'dog': 5,\n",
       "         'cat': 3,\n",
       "         'animal': 3,\n",
       "         'fish': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Negative sampling\n",
    "\n",
    "A function to get negative samples, based on the current center and outside words in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    #map(function, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#you don't want to pick samples = targets, basically negative samples\n",
    "#k = number of negative samples - how many? they found 10 is the best\n",
    "#will be run during training\n",
    "#after random_batch, \n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    #targets is already in id.....\n",
    "    #but the unigram_table is in word....\n",
    "    #1. get the batch size of this targets\n",
    "    batch_size = targets.shape[0]\n",
    "    neg_samples = []\n",
    "    #2. for each batch\n",
    "    for i in range(batch_size):\n",
    "        #randomly pick k negative words from unigram_table\n",
    "        target_index = targets[i].item()  #looping each of the batch....\n",
    "        nsample = []\n",
    "        while len(nsample) < k:\n",
    "            neg = random.choice(unigram_table)\n",
    "            #if this word == target, skip this word\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        #append this word to some list\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).reshape(1, -1))  #tensor[], tensor[]\n",
    "    return torch.cat(neg_samples)  #tensor[[], []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our negative sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [7]]),\n",
       " array([[6],\n",
       "        [1]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "input_batch, label_batch = random_batch(batch_size, corpus_tokenized)\n",
    "\n",
    "input_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = torch.LongTensor(input_batch)\n",
    "label_batch = torch.LongTensor(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neg = 5  #in the real code, we gonna use 10 (like in the paper)\n",
    "neg_samples = negative_sampling(label_batch, unigram_table, num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model\n",
    "\n",
    "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramNeg(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(SkipgramNeg, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "        \n",
    "    def forward(self, center_words, outside_words, negative_words):\n",
    "        #center_words, outside_words: (batch_size, 1)\n",
    "        #negative_words:  (batch_size, k)\n",
    "        \n",
    "        center_embed  = self.embedding_center_word(center_words)    #(batch_size, 1, emb_size)\n",
    "        outside_embed = self.embedding_outside_word(outside_words)  #(batch_size, 1, emb_size)\n",
    "        neg_embed     = self.embedding_outside_word(negative_words) #(batch_size, k, emb_size)\n",
    "        \n",
    "        uovc          =  outside_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, 1)\n",
    "        ukvc          = -neg_embed.bmm(center_embed.transpose(1, 2)).squeeze(2)  #(batch_size, k)\n",
    "        ukvc_sum      =  torch.sum(ukvc, 1).view(-1, 1) #(batch_size, 1)\n",
    "        \n",
    "        loss = self.logsigmoid(uovc) + self.logsigmoid(ukvc_sum)  #(batch_size, 1) + (batch_size, 1)\n",
    "                \n",
    "        return -torch.mean(loss)  #scalar, loss should be scalar, to call backward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, label = random_batch(batch_size, corpus_tokenized)\n",
    "input_tensor = torch.LongTensor(input)  \n",
    "label_tensor = torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 2 #usually, this can be 50, 100, or 300\n",
    "voc_size = len(vocabs)\n",
    "model = SkipgramNeg(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tensor = negative_sampling(label_tensor, unigram_table, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape, label_tensor.shape#, neg_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should give one number\n",
    "loss = model(input_tensor, label_tensor, neg_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0527, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size   = len(vocabs)\n",
    "batch_size = 2 #why?  no reason; \n",
    "emb_size   = 2 #why?  no reason; usually 50, 100, 300, but 2 so we can plot (50 can also plot, but need PCA)\n",
    "model      = SkipgramNeg(voc_size, emb_size)\n",
    "\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Loss: 0.811026 | Time: ??\n",
      "Epoch 2000 | Loss: 0.354529 | Time: ??\n",
      "Epoch 3000 | Loss: 0.228919 | Time: ??\n",
      "Epoch 4000 | Loss: 0.064696 | Time: ??\n",
      "Epoch 5000 | Loss: 0.173528 | Time: ??\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5000\n",
    "#for epoch\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    #get random batch\n",
    "    input_batch, label_batch = random_batch(batch_size, corpus)\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    label_batch = torch.LongTensor(label_batch)\n",
    "    neg_batch   = negative_sampling(label_batch, unigram_table, 5)    \n",
    "    \n",
    "    #loss = model\n",
    "    loss = model(input_batch, label_batch, neg_batch)\n",
    "    \n",
    "    #backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    #update alpha\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print epoch loss\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss:.6f} | Time: ??\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the embeddings\n",
    "\n",
    "Is really the related stuff are close to each other, and vice versa?\n",
    "\n",
    "The most fun part:  Will \"banana\" closer to \"fruit\" than \"cat\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['banana', 'cat', 'grape', 'fruit', 'fish', 'apple', 'animal', 'dog', '<UNK>']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana = torch.LongTensor([word2index['banana']])\n",
    "banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9417, -3.6350]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana_center_embed = model.embedding_center_word(banana)\n",
    "banana_outisde_embed = model.embedding_outside_word(banana)\n",
    "\n",
    "banana_embed = (banana_center_embed + banana_outisde_embed) / 2\n",
    "banana_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "    \n",
    "    word = torch.LongTensor([index])\n",
    "\n",
    "    center_embed  = model.embedding_center_word(word)\n",
    "    outside_embed = model.embedding_outside_word(word)\n",
    "    \n",
    "    embed = (center_embed + outside_embed) / 2\n",
    "    \n",
    "    return  embed[0][0].item(), embed[0][1].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.365776538848877, -2.8166699409484863)\n",
      "(-0.8624510765075684, 4.279304027557373)\n",
      "(0.4309408664703369, 3.8758819103240967)\n"
     ]
    }
   ],
   "source": [
    "#find embedding of fruit, cat\n",
    "print(get_embed('fruit'))\n",
    "print(get_embed('cat'))\n",
    "\n",
    "print(get_embed('chaky'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#help me plot fruit cat banana on matplotlib\n",
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cosine similarity\n",
    "\n",
    "How do (from scratch) calculate cosine similarity?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Oct 26 2021, 07:25:54) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
